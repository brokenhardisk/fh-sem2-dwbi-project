{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the input data as dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('../credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    psql_config = {\n",
    "    'dbname': data['db_name'],\n",
    "    'user': data['db_user'],\n",
    "    'password': data['db_pwd'],\n",
    "    'host': data['db_host'],\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "\n",
    "def get_psql_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**psql_config)\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tripduration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "starttime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "stoptime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "start_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "start_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bikeid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "usertype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "processed",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "994cb6b9-a145-4d98-9520-c317b7ac863c",
       "rows": [
        [
         "0",
         "176",
         "2018-02-08 18:19:27.370000",
         "2018-02-08 18:22:23.376000",
         "314",
         "Cadman Plaza West & Montague St",
         "40.69383",
         "-73.990539",
         "391",
         "Clark St & Henry St",
         "40.69760127",
         "-73.99344559",
         "21643",
         "Subscriber",
         "1986",
         "2",
         "False"
        ],
        [
         "1",
         "258",
         "2018-02-08 18:47:03.281000",
         "2018-02-08 18:51:21.659000",
         "314",
         "Cadman Plaza West & Montague St",
         "40.69383",
         "-73.990539",
         "407",
         "Henry St & Poplar St",
         "40.700469",
         "-73.991454",
         "32405",
         "Subscriber",
         "1971",
         "2",
         "False"
        ],
        [
         "2",
         "389",
         "2018-02-08 18:51:08.796000",
         "2018-02-08 18:57:38.442000",
         "314",
         "Cadman Plaza West & Montague St",
         "40.69383",
         "-73.990539",
         "3407",
         "Union St & Nevins St",
         "40.67909799721684",
         "-73.98765474557877",
         "32214",
         "Subscriber",
         "1979",
         "1",
         "False"
        ],
        [
         "3",
         "162",
         "2018-02-08 18:51:49.820000",
         "2018-02-08 18:54:32.161000",
         "314",
         "Cadman Plaza West & Montague St",
         "40.69383",
         "-73.990539",
         "406",
         "Hicks St & Montague St",
         "40.69512845",
         "-73.99595065",
         "21566",
         "Subscriber",
         "1962",
         "1",
         "False"
        ],
        [
         "4",
         "616",
         "2018-02-08 19:08:12.738000",
         "2018-02-08 19:18:28.853000",
         "314",
         "Cadman Plaza West & Montague St",
         "40.69383",
         "-73.990539",
         "3407",
         "Union St & Nevins St",
         "40.67909799721684",
         "-73.98765474557877",
         "16798",
         "Subscriber",
         "1957",
         "1",
         "False"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176</td>\n",
       "      <td>2018-02-08 18:19:27.370</td>\n",
       "      <td>2018-02-08 18:22:23.376</td>\n",
       "      <td>314</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.69383</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>391</td>\n",
       "      <td>Clark St &amp; Henry St</td>\n",
       "      <td>40.697601</td>\n",
       "      <td>-73.993446</td>\n",
       "      <td>21643</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1986</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>2018-02-08 18:47:03.281</td>\n",
       "      <td>2018-02-08 18:51:21.659</td>\n",
       "      <td>314</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.69383</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>407</td>\n",
       "      <td>Henry St &amp; Poplar St</td>\n",
       "      <td>40.700469</td>\n",
       "      <td>-73.991454</td>\n",
       "      <td>32405</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1971</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389</td>\n",
       "      <td>2018-02-08 18:51:08.796</td>\n",
       "      <td>2018-02-08 18:57:38.442</td>\n",
       "      <td>314</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.69383</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>3407</td>\n",
       "      <td>Union St &amp; Nevins St</td>\n",
       "      <td>40.679098</td>\n",
       "      <td>-73.987655</td>\n",
       "      <td>32214</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>2018-02-08 18:51:49.820</td>\n",
       "      <td>2018-02-08 18:54:32.161</td>\n",
       "      <td>314</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.69383</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>406</td>\n",
       "      <td>Hicks St &amp; Montague St</td>\n",
       "      <td>40.695128</td>\n",
       "      <td>-73.995951</td>\n",
       "      <td>21566</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1962</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616</td>\n",
       "      <td>2018-02-08 19:08:12.738</td>\n",
       "      <td>2018-02-08 19:18:28.853</td>\n",
       "      <td>314</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.69383</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>3407</td>\n",
       "      <td>Union St &amp; Nevins St</td>\n",
       "      <td>40.679098</td>\n",
       "      <td>-73.987655</td>\n",
       "      <td>16798</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           176 2018-02-08 18:19:27.370 2018-02-08 18:22:23.376   \n",
       "1           258 2018-02-08 18:47:03.281 2018-02-08 18:51:21.659   \n",
       "2           389 2018-02-08 18:51:08.796 2018-02-08 18:57:38.442   \n",
       "3           162 2018-02-08 18:51:49.820 2018-02-08 18:54:32.161   \n",
       "4           616 2018-02-08 19:08:12.738 2018-02-08 19:18:28.853   \n",
       "\n",
       "   start_station_id               start_station_name  start_station_latitude  \\\n",
       "0               314  Cadman Plaza West & Montague St                40.69383   \n",
       "1               314  Cadman Plaza West & Montague St                40.69383   \n",
       "2               314  Cadman Plaza West & Montague St                40.69383   \n",
       "3               314  Cadman Plaza West & Montague St                40.69383   \n",
       "4               314  Cadman Plaza West & Montague St                40.69383   \n",
       "\n",
       "   start_station_longitude  end_station_id        end_station_name  \\\n",
       "0               -73.990539             391     Clark St & Henry St   \n",
       "1               -73.990539             407    Henry St & Poplar St   \n",
       "2               -73.990539            3407    Union St & Nevins St   \n",
       "3               -73.990539             406  Hicks St & Montague St   \n",
       "4               -73.990539            3407    Union St & Nevins St   \n",
       "\n",
       "   end_station_latitude  end_station_longitude  bikeid    usertype  \\\n",
       "0             40.697601             -73.993446   21643  Subscriber   \n",
       "1             40.700469             -73.991454   32405  Subscriber   \n",
       "2             40.679098             -73.987655   32214  Subscriber   \n",
       "3             40.695128             -73.995951   21566  Subscriber   \n",
       "4             40.679098             -73.987655   16798  Subscriber   \n",
       "\n",
       "   birth_year  gender  processed  \n",
       "0        1986       2      False  \n",
       "1        1971       2      False  \n",
       "2        1979       1      False  \n",
       "3        1962       1      False  \n",
       "4        1957       1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(f'postgresql://{psql_config[\"user\"]}:{psql_config[\"password\"]}@{psql_config[\"host\"]}/{psql_config[\"dbname\"]}')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM m024.citi_bike_data LIMIT 1000;\", engine)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we will start processing it in bunch.\n",
    "For each chunk, we will apply some validation and transform the source data into fact and dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from psycopg2.extras import execute_values\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Function to calculate distance using Haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "# Extract Data\n",
    "def extract_data(offset):\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM m024.citi_bike_data \n",
    "    WHERE processed = FALSE \n",
    "    ORDER BY starttime \n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Load data into dimension tables\n",
    "def load_dimension_data(df, table_name, cols, db_cols):\n",
    "    df = df[cols].drop_duplicates()\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_{table_name} ({', '.join(db_cols)})\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table {table_name}- {e}\")\n",
    "\n",
    "# Load dimension tables and return mapping IDs\n",
    "def get_dimension_id(df, table_name, lookup_col, db_lookup_col,db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "    query = f\"SELECT {db_lookup_col}, {db_return_col} FROM m024.p_{table_name} WHERE {db_lookup_col} IN %s\"\n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_values),))\n",
    "    return dict(zip(mapping[db_lookup_col], mapping[db_return_col]))\n",
    "\n",
    "def get_time_dimension_id(df, table_name, lookup_col, db_lookup_cols, db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "\n",
    "    # Build query based on date components to avoid precision issues with timestamps\n",
    "    query = f\"\"\"\n",
    "    SELECT {', '.join(db_lookup_cols)}, {db_return_col}\n",
    "    FROM m024.p_{table_name}\n",
    "    WHERE ({', '.join(db_lookup_cols)}) IN %s\n",
    "    \"\"\"\n",
    "    lookup_tuples = [\n",
    "        (row['year'], row['month'], row['day'], row['hour']) for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_tuples),))\n",
    "    return dict(zip(mapping[db_lookup_cols], mapping[db_return_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Error in inserting/updating data for table user_birthyear_dimension- can't adapt type 'numpy.int64'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/jrmfwj7j0_dbkd43l1hrgy9m0000gn/T/ipykernel_12950/769035097.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['start_station_latitude'].fillna('Unknown', inplace=True)\n",
      "/var/folders/wc/jrmfwj7j0_dbkd43l1hrgy9m0000gn/T/ipykernel_12950/769035097.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['start_station_longitude'].fillna('Unknown', inplace=True)\n",
      "/var/folders/wc/jrmfwj7j0_dbkd43l1hrgy9m0000gn/T/ipykernel_12950/769035097.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['end_station_latitude'].fillna('Unknown', inplace=True)\n",
      "/var/folders/wc/jrmfwj7j0_dbkd43l1hrgy9m0000gn/T/ipykernel_12950/769035097.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['end_station_longitude'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n"
     ]
    },
    {
     "ename": "ObjectNotExecutableError",
     "evalue": "Not an executable object: 'UPDATE m024.citi_bike_data SET processed = TRUE WHERE processed = FALSE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/deng/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1414\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[43mstatement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_on_connection\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_execute_on_connection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mObjectNotExecutableError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 113\u001b[0m\n\u001b[1;32m    109\u001b[0m         update_processed()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;241m+\u001b[39mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 109\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(offset)\u001b[0m\n\u001b[1;32m    107\u001b[0m df_transformed \u001b[38;5;241m=\u001b[39m transform_data(df)\n\u001b[1;32m    108\u001b[0m load_fact_table(df_transformed)\n\u001b[0;32m--> 109\u001b[0m \u001b[43mupdate_processed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;241m+\u001b[39mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 101\u001b[0m, in \u001b[0;36mupdate_processed\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_processed\u001b[39m():\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m--> 101\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUPDATE m024.citi_bike_data SET processed = TRUE WHERE processed = FALSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deng/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1420\u001b[0m         distilled_parameters,\n\u001b[1;32m   1421\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[1;32m   1422\u001b[0m     )\n",
      "\u001b[0;31mObjectNotExecutableError\u001b[0m: Not an executable object: 'UPDATE m024.citi_bike_data SET processed = TRUE WHERE processed = FALSE'"
     ]
    }
   ],
   "source": [
    "# Transform Data\n",
    "def transform_data(df):\n",
    "    #transform gender and load the dimension\n",
    "    df.gender = df.gender.map(dict(zip([1, 2],['Male','Female']))).fillna('Unknown')\n",
    "    load_dimension_data(df, 'gender_dimension', ['gender'],['gender_type'])\n",
    "    df.usertype = df.usertype.apply(lambda x: x if x in ['Subscriber', 'Customer'] else 'Unknown')\n",
    "    load_dimension_data(df, 'user_type_dimension', ['usertype'],['user_type'])\n",
    "    #df['birth_year'] = df['birth_year'].apply(lambda x: int(x) if isinstance(x, (int, np.int64)) else 0)\n",
    "    df.birth_year = df.birth_year.apply(lambda x: x if x > 1940 and x <2013 else 0) # Assuming you need to be atleast 5 to ride the bike\n",
    "    load_dimension_data(df, 'user_birthyear_dimension', ['birth_year'],['user_birthyear'])\n",
    "\n",
    "    # Clean station names\n",
    "    df['start_station_name'] = df['start_station_name'].str.strip().fillna('Unknown')\n",
    "    df['end_station_name'] = df['end_station_name'].str.strip().fillna('Unknown')\n",
    "\n",
    "    # Validate Latitude and Longitude\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "\n",
    "    # For missing latitude/longitude values\n",
    "    df['start_station_latitude'].fillna('Unknown', inplace=True)\n",
    "    df['start_station_longitude'].fillna('Unknown', inplace=True)\n",
    "    df['end_station_latitude'].fillna('Unknown', inplace=True)\n",
    "    df['end_station_longitude'].fillna('Unknown', inplace=True)\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['starttime'].fillna('1.1.1900', inplace=True)\n",
    "    df['stoptime'].fillna('1.1.1900', inplace=True)\n",
    "\n",
    "    # Convert to datetime format\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'bike_dimension', ['bikeid'], ['bike_id'])\n",
    "\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    # Calculate trip distance\n",
    "    df['distance'] = df.apply(lambda row: haversine(\n",
    "        row['start_station_latitude'], row['start_station_longitude'], \n",
    "        row['end_station_latitude'], row['end_station_longitude']\n",
    "    ), axis=1)\n",
    "\n",
    "    # Get dimension table mappings\n",
    "    station_map = get_dimension_id(df, 'station_dimension', 'start_station_id', 'station_key','station_id')\n",
    "    end_station_map = get_dimension_id(df, 'station_dimension', 'end_station_id', 'station_key','station_id')\n",
    "    start_time_map = get_dimension_id(df, 'time_dimension', 'starttime', 'time', 'time_id')\n",
    "    stop_time_map = get_dimension_id(df, 'time_dimension', 'stoptime', 'time', 'time_id')\n",
    "    user_type_map = get_dimension_id(df, 'user_type_dimension', 'usertype', 'user_type','user_type_id')\n",
    "    gender_map = get_dimension_id(df, 'gender_dimension', 'gender', 'gender_type','gender_id')\n",
    "    birth_year_map = get_dimension_id(df, 'user_birthyear_dimension', 'birth_year', 'user_birthyear', 'user_birthyear_id')\n",
    "\n",
    "    # Map dimension table IDs\n",
    "    df['start_time_id'] = df['starttime'].map(start_time_map)\n",
    "    df['end_time_id'] = df['stoptime'].map(stop_time_map)\n",
    "    df['start_station_id'] = df['start_station_id'].map(station_map)\n",
    "    df['end_station_id'] = df['end_station_id'].map(end_station_map)\n",
    "    df['bike_id'] = df['bikeid']\n",
    "    df['user_type_id'] = df['usertype'].map(user_type_map)\n",
    "    df['gender_type_id'] = df['gender'].map(gender_map)\n",
    "    df['user_birthyear_id'] = df['birth_year'].map(birth_year_map)\n",
    "    df['duration'] = df['tripduration']\n",
    "\n",
    "    return df[['duration', 'distance', 'start_time_id', 'end_time_id', 'start_station_id', 'end_station_id', 'bike_id', 'user_type_id', 'gender_type_id', 'user_birthyear_id']]\n",
    "\n",
    "# Load fact table\n",
    "def load_fact_table(df):\n",
    "    df.to_sql('m024.p_trip_fact', con=engine, if_exists='append', index=False, method='multi', chunksize=10000)\n",
    "\n",
    "# Update processed records\n",
    "def update_processed(df):\n",
    "    query = \"UPDATE m024.citi_bike_data SET processed = TRUE WHERE processed = FALSE\"\n",
    "    \n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Execute the update statement\n",
    "                cur.execute(query)\n",
    "                conn.commit()  # Commit the changes\n",
    "                print(\"Successfully updated the processed flag.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating processed flag: {e}\")\n",
    "\n",
    "# Process batch\n",
    "def process_batch(offset):\n",
    "    df = extract_data(offset)\n",
    "    if not df.empty:\n",
    "        df_transformed = transform_data(df)\n",
    "        load_fact_table(df_transformed)\n",
    "        update_processed(df)\n",
    "        print(f\"Processed batch {offset}-{offset+BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "process_batch(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
