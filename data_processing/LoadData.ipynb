{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the input data as dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('../credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    psql_config = {\n",
    "    'dbname': data['db_name'],\n",
    "    'user': data['db_user'],\n",
    "    'password': data['db_pwd'],\n",
    "    'host': data['db_host'],\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "\n",
    "def get_psql_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**psql_config)\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tripduration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "starttime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "stoptime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "start_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "start_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bikeid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "usertype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "processed",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0dab8f3b-3acf-4720-903e-2b09daad97ec",
       "rows": [
        [
         "0",
         "618",
         "2018-01-03 15:46:02.261000",
         "2018-01-03 15:56:20.945000",
         "161",
         "LaGuardia Pl & W 3 St",
         "40.72917025",
         "-73.99810231",
         "504",
         "1 Ave & E 16 St",
         "40.73221853",
         "-73.98165557",
         "25336",
         "Subscriber",
         "1992",
         "1",
         "True",
         "2269047"
        ],
        [
         "1",
         "2021",
         "2018-07-22 15:45:38.495000",
         "2018-07-22 16:19:20.462000",
         "3671",
         "E 81 St & 2 Ave",
         "40.774779448957275",
         "-73.95427465438843",
         "3116",
         "Huron St & Franklin St",
         "40.73266",
         "-73.95826",
         "17396",
         "Subscriber",
         "1989",
         "1",
         "True",
         "2219451"
        ],
        [
         "2",
         "1803",
         "2018-07-12 08:32:30.275000",
         "2018-07-12 09:02:34.112000",
         "3552",
         "W 113 St & Broadway",
         "40.805973",
         "-73.964928",
         "442",
         "W 27 St & 7 Ave",
         "40.746647",
         "-73.993915",
         "31583",
         "Subscriber",
         "1964",
         "2",
         "True",
         "2118225"
        ],
        [
         "3",
         "305",
         "2018-07-04 11:36:21.970000",
         "2018-07-04 11:41:27.841000",
         "3579",
         "Sterling Pl & Bedford Ave",
         "40.672695",
         "-73.954131",
         "436",
         "Hancock St & Bedford Ave",
         "40.68216564",
         "-73.95399026",
         "31999",
         "Subscriber",
         "1994",
         "1",
         "True",
         "2139022"
        ],
        [
         "4",
         "334",
         "2018-07-24 20:21:01.921000",
         "2018-07-24 20:26:36.023000",
         "3570",
         "35 Ave & 37 St",
         "40.7557327",
         "-73.9236611",
         "3598",
         "Newton Rd & 44 St",
         "40.7595701",
         "-73.9142678",
         "30799",
         "Subscriber",
         "1980",
         "1",
         "True",
         "2131771"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>processed</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618</td>\n",
       "      <td>2018-01-03 15:46:02.261</td>\n",
       "      <td>2018-01-03 15:56:20.945</td>\n",
       "      <td>161</td>\n",
       "      <td>LaGuardia Pl &amp; W 3 St</td>\n",
       "      <td>40.729170</td>\n",
       "      <td>-73.998102</td>\n",
       "      <td>504</td>\n",
       "      <td>1 Ave &amp; E 16 St</td>\n",
       "      <td>40.732219</td>\n",
       "      <td>-73.981656</td>\n",
       "      <td>25336</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2269047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2018-07-22 15:45:38.495</td>\n",
       "      <td>2018-07-22 16:19:20.462</td>\n",
       "      <td>3671</td>\n",
       "      <td>E 81 St &amp; 2 Ave</td>\n",
       "      <td>40.774779</td>\n",
       "      <td>-73.954275</td>\n",
       "      <td>3116</td>\n",
       "      <td>Huron St &amp; Franklin St</td>\n",
       "      <td>40.732660</td>\n",
       "      <td>-73.958260</td>\n",
       "      <td>17396</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2219451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803</td>\n",
       "      <td>2018-07-12 08:32:30.275</td>\n",
       "      <td>2018-07-12 09:02:34.112</td>\n",
       "      <td>3552</td>\n",
       "      <td>W 113 St &amp; Broadway</td>\n",
       "      <td>40.805973</td>\n",
       "      <td>-73.964928</td>\n",
       "      <td>442</td>\n",
       "      <td>W 27 St &amp; 7 Ave</td>\n",
       "      <td>40.746647</td>\n",
       "      <td>-73.993915</td>\n",
       "      <td>31583</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1964</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2118225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>305</td>\n",
       "      <td>2018-07-04 11:36:21.970</td>\n",
       "      <td>2018-07-04 11:41:27.841</td>\n",
       "      <td>3579</td>\n",
       "      <td>Sterling Pl &amp; Bedford Ave</td>\n",
       "      <td>40.672695</td>\n",
       "      <td>-73.954131</td>\n",
       "      <td>436</td>\n",
       "      <td>Hancock St &amp; Bedford Ave</td>\n",
       "      <td>40.682166</td>\n",
       "      <td>-73.953990</td>\n",
       "      <td>31999</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2139022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>334</td>\n",
       "      <td>2018-07-24 20:21:01.921</td>\n",
       "      <td>2018-07-24 20:26:36.023</td>\n",
       "      <td>3570</td>\n",
       "      <td>35 Ave &amp; 37 St</td>\n",
       "      <td>40.755733</td>\n",
       "      <td>-73.923661</td>\n",
       "      <td>3598</td>\n",
       "      <td>Newton Rd &amp; 44 St</td>\n",
       "      <td>40.759570</td>\n",
       "      <td>-73.914268</td>\n",
       "      <td>30799</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2131771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           618 2018-01-03 15:46:02.261 2018-01-03 15:56:20.945   \n",
       "1          2021 2018-07-22 15:45:38.495 2018-07-22 16:19:20.462   \n",
       "2          1803 2018-07-12 08:32:30.275 2018-07-12 09:02:34.112   \n",
       "3           305 2018-07-04 11:36:21.970 2018-07-04 11:41:27.841   \n",
       "4           334 2018-07-24 20:21:01.921 2018-07-24 20:26:36.023   \n",
       "\n",
       "   start_station_id         start_station_name  start_station_latitude  \\\n",
       "0               161      LaGuardia Pl & W 3 St               40.729170   \n",
       "1              3671            E 81 St & 2 Ave               40.774779   \n",
       "2              3552        W 113 St & Broadway               40.805973   \n",
       "3              3579  Sterling Pl & Bedford Ave               40.672695   \n",
       "4              3570             35 Ave & 37 St               40.755733   \n",
       "\n",
       "   start_station_longitude  end_station_id          end_station_name  \\\n",
       "0               -73.998102             504           1 Ave & E 16 St   \n",
       "1               -73.954275            3116    Huron St & Franklin St   \n",
       "2               -73.964928             442           W 27 St & 7 Ave   \n",
       "3               -73.954131             436  Hancock St & Bedford Ave   \n",
       "4               -73.923661            3598         Newton Rd & 44 St   \n",
       "\n",
       "   end_station_latitude  end_station_longitude  bikeid    usertype  \\\n",
       "0             40.732219             -73.981656   25336  Subscriber   \n",
       "1             40.732660             -73.958260   17396  Subscriber   \n",
       "2             40.746647             -73.993915   31583  Subscriber   \n",
       "3             40.682166             -73.953990   31999  Subscriber   \n",
       "4             40.759570             -73.914268   30799  Subscriber   \n",
       "\n",
       "   birth_year  gender  processed       id  \n",
       "0        1992       1       True  2269047  \n",
       "1        1989       1       True  2219451  \n",
       "2        1964       2       True  2118225  \n",
       "3        1994       1       True  2139022  \n",
       "4        1980       1       True  2131771  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(f'postgresql://{psql_config[\"user\"]}:{psql_config[\"password\"]}@{psql_config[\"host\"]}/{psql_config[\"dbname\"]}')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM m024.citi_bike_data LIMIT 1000;\", engine)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we will start processing it in bunch.\n",
    "For each chunk, we will apply some validation and transform the source data into fact and dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from psycopg2.extras import execute_values\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "# Function to calculate distance using Haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "# Extract Data\n",
    "def extract_data(last_id):\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM m024.citi_bike_data \n",
    "    WHERE processed = FALSE AND id > {last_id}\n",
    "    ORDER BY id\n",
    "    LIMIT {BATCH_SIZE}\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Load data into dimension tables\n",
    "def load_dimension_data(df, table_name, cols, db_cols):\n",
    "    df = df[cols].astype('str').drop_duplicates()\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_{table_name} ({', '.join(db_cols)})\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table {table_name}- {e}\")\n",
    "\n",
    "# Load dimension tables and return mapping IDs\n",
    "def get_dimension_id(df, table_name, lookup_col, db_lookup_col,db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "    query = f\"SELECT {db_lookup_col}, {db_return_col} FROM m024.p_{table_name} WHERE {db_lookup_col} IN %s\"\n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_values),))\n",
    "    return dict(zip(mapping[db_lookup_col], mapping[db_return_col]))\n",
    "\n",
    "def get_time_dimension_id(df, table_name, lookup_col, db_lookup_cols, db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "\n",
    "    # Build query based on date components to avoid precision issues with timestamps\n",
    "    query = f\"\"\"\n",
    "    SELECT {', '.join(db_lookup_cols)}, {db_return_col}\n",
    "    FROM m024.p_{table_name}\n",
    "    WHERE ({', '.join(db_lookup_cols)}) IN %s\n",
    "    \"\"\"\n",
    "    lookup_tuples = [\n",
    "        (row['year'], row['month'], row['day'], row['hour']) for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_tuples),))\n",
    "    return dict(zip(mapping[db_lookup_cols], mapping[db_return_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 8500000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 8600000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 8700000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 8800000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 8900000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9000000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9100000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9200000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9300000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9400000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9500000\n",
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 9537761\n",
      "No more records to process.\n"
     ]
    }
   ],
   "source": [
    "# Transform Data\n",
    "def transform_data(df):\n",
    "\n",
    "    # transform gender and load the dimension\n",
    "    df.gender = df.gender.map(dict(zip([1, 2],['Male','Female']))).fillna('Unknown')\n",
    "    load_dimension_data(df, 'gender_dimension', ['gender'],['gender_type'])\n",
    "\n",
    "    # transform user type and load the dimension\n",
    "    df.usertype = df.usertype.apply(lambda x: x if x in ['Subscriber', 'Customer'] else 'Unknown')\n",
    "    load_dimension_data(df, 'user_type_dimension', ['usertype'],['user_type'])\n",
    "\n",
    "    # transform birth year and load the dimension\n",
    "    df.birth_year = df.birth_year.apply(lambda x: x if x > 1940 and x <2013 else 0).astype(int) # Assuming you need to be atleast 5 to ride the bike\n",
    "    load_dimension_data(df, 'user_birthyear_dimension', ['birth_year'],['user_birthyear'])\n",
    "\n",
    "    # Clean station names\n",
    "    df['start_station_name'] = df['start_station_name'].str.strip().fillna('Unknown')\n",
    "    df['end_station_name'] = df['end_station_name'].str.strip().fillna('Unknown')\n",
    "\n",
    "    # Validate Latitude and Longitude\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "\n",
    "    # For missing latitude/longitude values\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].fillna('Unknown')\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].fillna('Unknown')\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].fillna('Unknown')\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].fillna('Unknown')\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['starttime'] = df['starttime'].fillna('1.1.1900')\n",
    "    df['stoptime'] = df['stoptime'].fillna('1.1.1900')\n",
    "\n",
    "    # Convert to datetime format\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'bike_dimension', ['bikeid'], ['bike_id'])\n",
    "\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    # Calculate trip distance\n",
    "    df['distance'] = df.apply(lambda row: haversine(\n",
    "        row['start_station_latitude'], row['start_station_longitude'], \n",
    "        row['end_station_latitude'], row['end_station_longitude']\n",
    "    ), axis=1)\n",
    "\n",
    "    # Get dimension table mappings\n",
    "    station_map = get_dimension_id(df, 'station_dimension', 'start_station_id', 'station_key','station_id')\n",
    "    end_station_map = get_dimension_id(df, 'station_dimension', 'end_station_id', 'station_key','station_id')\n",
    "    start_time_map = get_dimension_id(df, 'time_dimension', 'starttime', 'time', 'time_id')\n",
    "    stop_time_map = get_dimension_id(df, 'time_dimension', 'stoptime', 'time', 'time_id')\n",
    "    user_type_map = get_dimension_id(df, 'user_type_dimension', 'usertype', 'user_type','user_type_id')\n",
    "    gender_map = get_dimension_id(df, 'gender_dimension', 'gender', 'gender_type','gender_id')\n",
    "    birth_year_map = get_dimension_id(df, 'user_birthyear_dimension', 'birth_year', 'user_birthyear', 'user_birthyear_id')\n",
    "\n",
    "    # Map dimension table IDs\n",
    "    df['start_time_id'] = df['starttime'].map(start_time_map)\n",
    "    df['end_time_id'] = df['stoptime'].map(stop_time_map)\n",
    "    df['start_station_id'] = df['start_station_id'].map(station_map)\n",
    "    df['end_station_id'] = df['end_station_id'].map(end_station_map)\n",
    "    df['bike_id'] = df['bikeid']\n",
    "    df['user_type_id'] = df['usertype'].map(user_type_map)\n",
    "    df['gender_type_id'] = df['gender'].map(gender_map)\n",
    "    df['user_birthyear_id'] = df['birth_year'].map(birth_year_map)\n",
    "    df['duration'] = df['tripduration']\n",
    "\n",
    "    return df[['id','duration', 'distance', 'start_time_id', 'end_time_id', 'start_station_id', 'end_station_id', 'bike_id', 'user_type_id', 'gender_type_id', 'user_birthyear_id']]\n",
    "\n",
    "# Update processed records\n",
    "def update_processed(ids):\n",
    "    if not ids:\n",
    "        return\n",
    "    query = f\"\"\"\n",
    "    UPDATE m024.citi_bike_data\n",
    "    SET processed = TRUE\n",
    "    WHERE id IN (SELECT UNNEST(%s));\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, (ids,))\n",
    "                conn.commit()\n",
    "                print(f\"Successfully updated the processed flag for {BATCH_SIZE} rows).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating processed flag: {e}\")\n",
    "\n",
    "# Process batch\n",
    "def process_batch(last_id):\n",
    "    df = extract_data(last_id)\n",
    "    if df.empty:\n",
    "        print(\"No more records to process.\")\n",
    "        return None\n",
    "    \n",
    "    df_transformed = transform_data(df)\n",
    "    #Extract the ids \n",
    "    processed_ids = df_transformed['id'].tolist()\n",
    "\n",
    "    # Drop the ID column before loading fact table\n",
    "    df_transformed = df_transformed.drop(columns=['id'])\n",
    "\n",
    "    load_dimension_data(df_transformed, 'trip_fact', df_transformed.columns, df_transformed.columns)\n",
    "    \n",
    "    # Update processed flag for processed IDs\n",
    "    update_processed(processed_ids)\n",
    "    \n",
    "    # Get the max ID from the batch\n",
    "    max_id = max(processed_ids)\n",
    "    print(f\"Processed batch up to ID: {max_id}\")\n",
    "    return max_id\n",
    "\n",
    "\n",
    "last_id = 0\n",
    "#limit_record_id = 9600000\n",
    "while last_id != None:\n",
    "    last_id = process_batch(last_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
