{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the input data as dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('../credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    psql_config = {\n",
    "    'dbname': data['db_name'],\n",
    "    'user': data['db_user'],\n",
    "    'password': data['db_pwd'],\n",
    "    'host': data['db_host'],\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "\n",
    "def get_psql_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**psql_config)\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tripduration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "starttime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "stoptime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "start_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "start_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bikeid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "usertype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "processed",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "90048d0f-4521-4723-8bb2-0e20f399c248",
       "rows": [
        [
         "0",
         "468",
         "2018-06-03 09:25:25.025000",
         "2018-06-03 09:33:13.241000",
         "496",
         "E 16 St & 5 Ave",
         "40.73726186",
         "-73.99238967",
         "490",
         "8 Ave & W 33 St",
         "40.751551",
         "-73.993934",
         "32381",
         "Subscriber",
         "1970",
         "0",
         "False",
         "8846088"
        ],
        [
         "1",
         "1409",
         "2018-06-03 19:02:14.385000",
         "2018-06-03 19:25:43.571000",
         "494",
         "W 26 St & 8 Ave",
         "40.74734825",
         "-73.99723551",
         "377",
         "6 Ave & Canal St",
         "40.72243797",
         "-74.00566443",
         "28065",
         "Customer",
         "1969",
         "0",
         "False",
         "8834652"
        ],
        [
         "2",
         "1201",
         "2018-06-21 05:13:47.122000",
         "2018-06-21 05:33:48.125000",
         "487",
         "E 20 St & FDR Drive",
         "40.73314259",
         "-73.97573881",
         "3163",
         "Central Park West & W 68 St",
         "40.7734066",
         "-73.97782542",
         "31059",
         "Subscriber",
         "1989",
         "1",
         "False",
         "8806410"
        ],
        [
         "3",
         "755",
         "2018-06-02 11:39:15.912000",
         "2018-06-02 11:51:51.167000",
         "497",
         "E 17 St & Broadway",
         "40.73704984",
         "-73.99009296",
         "303",
         "Mercer St & Spring St",
         "40.72362738",
         "-73.99949601",
         "19635",
         "Subscriber",
         "1985",
         "2",
         "False",
         "8852254"
        ],
        [
         "4",
         "230",
         "2018-06-20 20:58:08.255000",
         "2018-06-20 21:01:59.219000",
         "494",
         "W 26 St & 8 Ave",
         "40.74734825",
         "-73.99723551",
         "3258",
         "W 27 St & 10 Ave",
         "40.75018156325683",
         "-74.00218427181244",
         "18669",
         "Subscriber",
         "1993",
         "2",
         "False",
         "8838835"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>processed</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468</td>\n",
       "      <td>2018-06-03 09:25:25.025</td>\n",
       "      <td>2018-06-03 09:33:13.241</td>\n",
       "      <td>496</td>\n",
       "      <td>E 16 St &amp; 5 Ave</td>\n",
       "      <td>40.737262</td>\n",
       "      <td>-73.992390</td>\n",
       "      <td>490</td>\n",
       "      <td>8 Ave &amp; W 33 St</td>\n",
       "      <td>40.751551</td>\n",
       "      <td>-73.993934</td>\n",
       "      <td>32381</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1970</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8846088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1409</td>\n",
       "      <td>2018-06-03 19:02:14.385</td>\n",
       "      <td>2018-06-03 19:25:43.571</td>\n",
       "      <td>494</td>\n",
       "      <td>W 26 St &amp; 8 Ave</td>\n",
       "      <td>40.747348</td>\n",
       "      <td>-73.997236</td>\n",
       "      <td>377</td>\n",
       "      <td>6 Ave &amp; Canal St</td>\n",
       "      <td>40.722438</td>\n",
       "      <td>-74.005664</td>\n",
       "      <td>28065</td>\n",
       "      <td>Customer</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8834652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201</td>\n",
       "      <td>2018-06-21 05:13:47.122</td>\n",
       "      <td>2018-06-21 05:33:48.125</td>\n",
       "      <td>487</td>\n",
       "      <td>E 20 St &amp; FDR Drive</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.975739</td>\n",
       "      <td>3163</td>\n",
       "      <td>Central Park West &amp; W 68 St</td>\n",
       "      <td>40.773407</td>\n",
       "      <td>-73.977825</td>\n",
       "      <td>31059</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8806410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755</td>\n",
       "      <td>2018-06-02 11:39:15.912</td>\n",
       "      <td>2018-06-02 11:51:51.167</td>\n",
       "      <td>497</td>\n",
       "      <td>E 17 St &amp; Broadway</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>303</td>\n",
       "      <td>Mercer St &amp; Spring St</td>\n",
       "      <td>40.723627</td>\n",
       "      <td>-73.999496</td>\n",
       "      <td>19635</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>8852254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230</td>\n",
       "      <td>2018-06-20 20:58:08.255</td>\n",
       "      <td>2018-06-20 21:01:59.219</td>\n",
       "      <td>494</td>\n",
       "      <td>W 26 St &amp; 8 Ave</td>\n",
       "      <td>40.747348</td>\n",
       "      <td>-73.997236</td>\n",
       "      <td>3258</td>\n",
       "      <td>W 27 St &amp; 10 Ave</td>\n",
       "      <td>40.750182</td>\n",
       "      <td>-74.002184</td>\n",
       "      <td>18669</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1993</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>8838835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           468 2018-06-03 09:25:25.025 2018-06-03 09:33:13.241   \n",
       "1          1409 2018-06-03 19:02:14.385 2018-06-03 19:25:43.571   \n",
       "2          1201 2018-06-21 05:13:47.122 2018-06-21 05:33:48.125   \n",
       "3           755 2018-06-02 11:39:15.912 2018-06-02 11:51:51.167   \n",
       "4           230 2018-06-20 20:58:08.255 2018-06-20 21:01:59.219   \n",
       "\n",
       "   start_station_id   start_station_name  start_station_latitude  \\\n",
       "0               496      E 16 St & 5 Ave               40.737262   \n",
       "1               494      W 26 St & 8 Ave               40.747348   \n",
       "2               487  E 20 St & FDR Drive               40.733143   \n",
       "3               497   E 17 St & Broadway               40.737050   \n",
       "4               494      W 26 St & 8 Ave               40.747348   \n",
       "\n",
       "   start_station_longitude  end_station_id             end_station_name  \\\n",
       "0               -73.992390             490              8 Ave & W 33 St   \n",
       "1               -73.997236             377             6 Ave & Canal St   \n",
       "2               -73.975739            3163  Central Park West & W 68 St   \n",
       "3               -73.990093             303        Mercer St & Spring St   \n",
       "4               -73.997236            3258             W 27 St & 10 Ave   \n",
       "\n",
       "   end_station_latitude  end_station_longitude  bikeid    usertype  \\\n",
       "0             40.751551             -73.993934   32381  Subscriber   \n",
       "1             40.722438             -74.005664   28065    Customer   \n",
       "2             40.773407             -73.977825   31059  Subscriber   \n",
       "3             40.723627             -73.999496   19635  Subscriber   \n",
       "4             40.750182             -74.002184   18669  Subscriber   \n",
       "\n",
       "   birth_year  gender  processed       id  \n",
       "0        1970       0      False  8846088  \n",
       "1        1969       0      False  8834652  \n",
       "2        1989       1      False  8806410  \n",
       "3        1985       2      False  8852254  \n",
       "4        1993       2      False  8838835  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(f'postgresql://{psql_config[\"user\"]}:{psql_config[\"password\"]}@{psql_config[\"host\"]}/{psql_config[\"dbname\"]}')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM m024.citi_bike_data LIMIT 1000;\", engine)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we will start processing it in bunch.\n",
    "For each chunk, we will apply some validation and transform the source data into fact and dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from psycopg2.extras import execute_values\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "# Function to calculate distance using Haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "# Extract Data\n",
    "def extract_data(last_id):\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM m024.citi_bike_data \n",
    "    WHERE processed = FALSE AND id > {last_id}\n",
    "    ORDER BY id\n",
    "    LIMIT {BATCH_SIZE}\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Load data into dimension tables\n",
    "def load_dimension_data(df, table_name, cols, db_cols):\n",
    "    df = df[cols].astype('str').drop_duplicates()\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_{table_name} ({', '.join(db_cols)})\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table {table_name}- {e}\")\n",
    "\n",
    "# Load dimension tables and return mapping IDs\n",
    "def get_dimension_id(df, table_name, lookup_col, db_lookup_col,db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "    query = f\"SELECT {db_lookup_col}, {db_return_col} FROM m024.p_{table_name} WHERE {db_lookup_col} IN %s\"\n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_values),))\n",
    "    return dict(zip(mapping[db_lookup_col], mapping[db_return_col]))\n",
    "\n",
    "def get_time_dimension_id(df, table_name, lookup_col, db_lookup_cols, db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "\n",
    "    # Build query based on date components to avoid precision issues with timestamps\n",
    "    query = f\"\"\"\n",
    "    SELECT {', '.join(db_lookup_cols)}, {db_return_col}\n",
    "    FROM m024.p_{table_name}\n",
    "    WHERE ({', '.join(db_lookup_cols)}) IN %s\n",
    "    \"\"\"\n",
    "    lookup_tuples = [\n",
    "        (row['year'], row['month'], row['day'], row['hour']) for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_tuples),))\n",
    "    return dict(zip(mapping[db_lookup_cols], mapping[db_return_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender\n",
      "0       0\n",
      "1       1\n",
      "2       2\n",
      "Data inserted/updated successfully in p_gender_dimension\n"
     ]
    }
   ],
   "source": [
    "# Create and update the gender dimension\n",
    "gender_map = {1:\"Male\",2:\"Female\"}\n",
    "def initUpdateGenderDimension():\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                select_st = f\"\"\"\n",
    "                SELECT DISTINCT gender from m024.citi_bike_data where processed = false;\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(select_st, engine)\n",
    "                print(df)\n",
    "                df.gender = df.gender.map(gender_map).fillna(\"Unknown\")\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_gender_dimension (gender_type)\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in p_gender_dimension\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table p_gender_dimension- {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "initUpdateGenderDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     usertype\n",
      "0    Customer\n",
      "1  Subscriber\n",
      "Data inserted/updated successfully in p_user_type_dimension\n"
     ]
    }
   ],
   "source": [
    "# Create and update the user type dimension\n",
    "user_type_map = {'Subscriber', 'Customer'}\n",
    "def initUpdateUserTypeDimension():\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                select_st = f\"\"\"\n",
    "                SELECT DISTINCT usertype from m024.citi_bike_data where processed = false;\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(select_st, engine)\n",
    "                print(df)\n",
    "                df.usertype = df.usertype.apply(lambda x: x if x in user_type_map else 'Unknown')\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_user_type_dimension (user_type)\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in p_user_type_dimension\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table p_user_type_dimension- {e}\")\n",
    "\n",
    "initUpdateUserTypeDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     birth_year\n",
      "0          1885\n",
      "1          1886\n",
      "2          1887\n",
      "3          1888\n",
      "4          1889\n",
      "..          ...\n",
      "100        1998\n",
      "101        1999\n",
      "102        2000\n",
      "103        2001\n",
      "104        2002\n",
      "\n",
      "[105 rows x 1 columns]\n",
      "Data inserted/updated successfully in p_user_birthyear_dimension\n"
     ]
    }
   ],
   "source": [
    "# Create and update the user birth year dimension\n",
    "def initUpdateBirthYearDimension():\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                select_st = f\"\"\"\n",
    "                SELECT DISTINCT birth_year from m024.citi_bike_data where processed = false;\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(select_st, engine)\n",
    "                print(df)\n",
    "                df.birth_year = df.birth_year.apply(lambda x: x if x > 1940 and x <2013 else 0).astype(\"str\").drop_duplicates() # Assuming you need to be atleast 5 to ride the bike\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_user_birthyear_dimension (user_birthyear)\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in p_user_birthyear_dimension\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table p_user_birthyear_dimension- {e}\")\n",
    "\n",
    "initUpdateBirthYearDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bikeid\n",
      "0       14529\n",
      "1       14530\n",
      "2       14532\n",
      "3       14533\n",
      "4       14534\n",
      "...       ...\n",
      "13091   33727\n",
      "13092   33728\n",
      "13093   33729\n",
      "13094   33730\n",
      "13095   33733\n",
      "\n",
      "[13096 rows x 1 columns]\n",
      "Data inserted/updated successfully in p_bike_dimension\n"
     ]
    }
   ],
   "source": [
    "# Create and update the bikeid dimension\n",
    "def initUpdateBikeIDDimension():\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                select_st = f\"\"\"\n",
    "                SELECT DISTINCT bikeid from m024.citi_bike_data where processed = false;\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(select_st, engine)\n",
    "                print(df)\n",
    "                df.bikeid = df.bikeid.astype(\"str\").drop_duplicates()\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_bike_dimension (bike_id)\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in p_bike_dimension\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table p_bike_dimension- {e}\")\n",
    "    \n",
    "initUpdateBikeIDDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and update the station dimension\n",
    "start_station_id, start_station_name,start_station_latitude,start_station_longitude,end_station_id,end_station_name,end_station_latitude,end_station_longitude\n",
    "def initUpdateStationDimension():\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                select_st = f\"\"\"\n",
    "                SELECT start_station_id, start_station_name, start_station_latitude, start_station_longitude,\n",
    "                end_station_id, end_station_name, end_station_latitude, end_station_longitude \n",
    "                from m024.citi_bike_data where processed = false;\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(select_st, engine)\n",
    "                print(df)\n",
    "                df.bikeid = df.bikeid.astype(\"str\").drop_duplicates()\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_station_dimension (bike_id)\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in p_bike_dimension\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table p_bike_dimension- {e}\")\n",
    "    \n",
    "initUpdateStationDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100000 rows).\n",
      "Processed batch up to ID: 100000\n"
     ]
    }
   ],
   "source": [
    "# Transform Data\n",
    "def transform_data(df):\n",
    "\n",
    "    # transform gender and load the dimension\n",
    "    df.gender = df.gender.map(dict(zip([1, 2],['Male','Female']))).fillna('Unknown')\n",
    "    #load_dimension_data(df, 'gender_dimension', ['gender'],['gender_type'])\n",
    "\n",
    "    # transform user type and load the dimension\n",
    "    df.usertype = df.usertype.apply(lambda x: x if x in ['Subscriber', 'Customer'] else 'Unknown')\n",
    "    #load_dimension_data(df, 'user_type_dimension', ['usertype'],['user_type'])\n",
    "\n",
    "    # transform birth year and load the dimension\n",
    "    df.birth_year = df.birth_year.apply(lambda x: x if x > 1940 and x <2013 else 0).astype(int) # Assuming you need to be atleast 5 to ride the bike\n",
    "    #load_dimension_data(df, 'user_birthyear_dimension', ['birth_year'],['user_birthyear'])\n",
    "\n",
    "    # Clean station names\n",
    "    df['start_station_name'] = df['start_station_name'].str.strip().fillna('Unknown')\n",
    "    df['end_station_name'] = df['end_station_name'].str.strip().fillna('Unknown')\n",
    "\n",
    "    # Validate Latitude and Longitude\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "\n",
    "    # For missing latitude/longitude values\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].fillna('Unknown')\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].fillna('Unknown')\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].fillna('Unknown')\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].fillna('Unknown')\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['starttime'] = df['starttime'].fillna('1.1.1900')\n",
    "    df['stoptime'] = df['stoptime'].fillna('1.1.1900')\n",
    "\n",
    "    # Convert to datetime format\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    #load_dimension_data(df, 'bike_dimension', ['bikeid'], ['bike_id'])\n",
    "\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    # Calculate trip distance\n",
    "    df['distance'] = df.apply(lambda row: haversine(\n",
    "        row['start_station_latitude'], row['start_station_longitude'], \n",
    "        row['end_station_latitude'], row['end_station_longitude']\n",
    "    ), axis=1)\n",
    "\n",
    "    # Get dimension table mappings\n",
    "    station_map = get_dimension_id(df, 'station_dimension', 'start_station_id', 'station_key','station_id')\n",
    "    end_station_map = get_dimension_id(df, 'station_dimension', 'end_station_id', 'station_key','station_id')\n",
    "    start_time_map = get_dimension_id(df, 'time_dimension', 'starttime', 'time', 'time_id')\n",
    "    stop_time_map = get_dimension_id(df, 'time_dimension', 'stoptime', 'time', 'time_id')\n",
    "    user_type_map = get_dimension_id(df, 'user_type_dimension', 'usertype', 'user_type','user_type_id')\n",
    "    gender_map = get_dimension_id(df, 'gender_dimension', 'gender', 'gender_type','gender_id')\n",
    "    birth_year_map = get_dimension_id(df, 'user_birthyear_dimension', 'birth_year', 'user_birthyear', 'user_birthyear_id')\n",
    "\n",
    "    # Map dimension table IDs\n",
    "    df['start_time_id'] = df['starttime'].map(start_time_map)\n",
    "    df['end_time_id'] = df['stoptime'].map(stop_time_map)\n",
    "    df['start_station_id'] = df['start_station_id'].map(station_map)\n",
    "    df['end_station_id'] = df['end_station_id'].map(end_station_map)\n",
    "    df['bike_id'] = df['bikeid']\n",
    "    df['user_type_id'] = df['usertype'].map(user_type_map)\n",
    "    df['gender_type_id'] = df['gender'].map(gender_map)\n",
    "    df['user_birthyear_id'] = df['birth_year'].map(birth_year_map)\n",
    "    df['duration'] = df['tripduration']\n",
    "\n",
    "    return df[['id','duration', 'distance', 'start_time_id', 'end_time_id', 'start_station_id', 'end_station_id', 'bike_id', 'user_type_id', 'gender_type_id', 'user_birthyear_id']]\n",
    "\n",
    "# Update processed records\n",
    "def update_processed(ids):\n",
    "    if not ids:\n",
    "        return\n",
    "    query = f\"\"\"\n",
    "    UPDATE m024.citi_bike_data\n",
    "    SET processed = TRUE\n",
    "    WHERE id IN (SELECT UNNEST(%s));\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query, (ids,))\n",
    "                conn.commit()\n",
    "                print(f\"Successfully updated the processed flag for {BATCH_SIZE} rows).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating processed flag: {e}\")\n",
    "\n",
    "# Process batch\n",
    "def process_batch(last_id):\n",
    "    df = extract_data(last_id)\n",
    "    if df.empty:\n",
    "        print(\"No more records to process.\")\n",
    "        return None\n",
    "    \n",
    "    df_transformed = transform_data(df)\n",
    "    #Extract the ids \n",
    "    processed_ids = df_transformed['id'].tolist()\n",
    "\n",
    "    # Drop the ID column before loading fact table\n",
    "    df_transformed = df_transformed.drop(columns=['id'])\n",
    "\n",
    "    load_dimension_data(df_transformed, 'trip_fact', df_transformed.columns, df_transformed.columns)\n",
    "    \n",
    "    # Update processed flag for processed IDs\n",
    "    update_processed(processed_ids)\n",
    "    \n",
    "    # Get the max ID from the batch\n",
    "    max_id = max(processed_ids)\n",
    "    print(f\"Processed batch up to ID: {max_id}\")\n",
    "    return max_id\n",
    "\n",
    "\n",
    "last_id = 0\n",
    "limit_record_id = 9999\n",
    "while last_id < limit_record_id:\n",
    "    last_id = process_batch(last_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
