{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the input data as dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open('../credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    psql_config = {\n",
    "    'dbname': data['db_name'],\n",
    "    'user': data['db_user'],\n",
    "    'password': data['db_pwd'],\n",
    "    'host': data['db_host'],\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "\n",
    "def get_psql_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**psql_config)\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tripduration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "starttime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "stoptime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "start_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "start_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_station_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_station_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bikeid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "usertype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "processed",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "68ca2bf4-4410-424b-be5d-166cc7521dac",
       "rows": [
        [
         "0",
         "314",
         "2018-04-15 12:17:02.635000",
         "2018-04-15 12:22:17.257000",
         "499",
         "Broadway & W 60 St",
         "40.76915505",
         "-73.98191841",
         "3175",
         "W 70 St & Amsterdam Ave",
         "40.77748046",
         "-73.98288594",
         "30250",
         "Subscriber",
         "1981",
         "1",
         "False"
        ],
        [
         "1",
         "329",
         "2018-04-15 12:26:40.715000",
         "2018-04-15 12:32:10.258000",
         "499",
         "Broadway & W 60 St",
         "40.76915505",
         "-73.98191841",
         "3167",
         "Amsterdam Ave & W 73 St",
         "40.77966809007312",
         "-73.98093044757842",
         "30491",
         "Subscriber",
         "1967",
         "1",
         "False"
        ],
        [
         "2",
         "124",
         "2018-04-15 12:38:16.050000",
         "2018-04-15 12:40:20.975000",
         "499",
         "Broadway & W 60 St",
         "40.76915505",
         "-73.98191841",
         "423",
         "W 54 St & 9 Ave",
         "40.76584941",
         "-73.98690506",
         "15480",
         "Subscriber",
         "1978",
         "1",
         "False"
        ],
        [
         "3",
         "248",
         "2018-04-15 12:43:27.859000",
         "2018-04-15 12:47:36.266000",
         "499",
         "Broadway & W 60 St",
         "40.76915505",
         "-73.98191841",
         "3175",
         "W 70 St & Amsterdam Ave",
         "40.77748046",
         "-73.98288594",
         "30922",
         "Subscriber",
         "1988",
         "1",
         "False"
        ],
        [
         "4",
         "1121",
         "2018-04-15 12:47:25.606000",
         "2018-04-15 13:06:07.452000",
         "499",
         "Broadway & W 60 St",
         "40.76915505",
         "-73.98191841",
         "3163",
         "Central Park West & W 68 St",
         "40.7734066",
         "-73.97782542",
         "32707",
         "Customer",
         "1990",
         "1",
         "False"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314</td>\n",
       "      <td>2018-04-15 12:17:02.635</td>\n",
       "      <td>2018-04-15 12:22:17.257</td>\n",
       "      <td>499</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>3175</td>\n",
       "      <td>W 70 St &amp; Amsterdam Ave</td>\n",
       "      <td>40.777480</td>\n",
       "      <td>-73.982886</td>\n",
       "      <td>30250</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>329</td>\n",
       "      <td>2018-04-15 12:26:40.715</td>\n",
       "      <td>2018-04-15 12:32:10.258</td>\n",
       "      <td>499</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>3167</td>\n",
       "      <td>Amsterdam Ave &amp; W 73 St</td>\n",
       "      <td>40.779668</td>\n",
       "      <td>-73.980930</td>\n",
       "      <td>30491</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>2018-04-15 12:38:16.050</td>\n",
       "      <td>2018-04-15 12:40:20.975</td>\n",
       "      <td>499</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>423</td>\n",
       "      <td>W 54 St &amp; 9 Ave</td>\n",
       "      <td>40.765849</td>\n",
       "      <td>-73.986905</td>\n",
       "      <td>15480</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248</td>\n",
       "      <td>2018-04-15 12:43:27.859</td>\n",
       "      <td>2018-04-15 12:47:36.266</td>\n",
       "      <td>499</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>3175</td>\n",
       "      <td>W 70 St &amp; Amsterdam Ave</td>\n",
       "      <td>40.777480</td>\n",
       "      <td>-73.982886</td>\n",
       "      <td>30922</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121</td>\n",
       "      <td>2018-04-15 12:47:25.606</td>\n",
       "      <td>2018-04-15 13:06:07.452</td>\n",
       "      <td>499</td>\n",
       "      <td>Broadway &amp; W 60 St</td>\n",
       "      <td>40.769155</td>\n",
       "      <td>-73.981918</td>\n",
       "      <td>3163</td>\n",
       "      <td>Central Park West &amp; W 68 St</td>\n",
       "      <td>40.773407</td>\n",
       "      <td>-73.977825</td>\n",
       "      <td>32707</td>\n",
       "      <td>Customer</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration               starttime                stoptime  \\\n",
       "0           314 2018-04-15 12:17:02.635 2018-04-15 12:22:17.257   \n",
       "1           329 2018-04-15 12:26:40.715 2018-04-15 12:32:10.258   \n",
       "2           124 2018-04-15 12:38:16.050 2018-04-15 12:40:20.975   \n",
       "3           248 2018-04-15 12:43:27.859 2018-04-15 12:47:36.266   \n",
       "4          1121 2018-04-15 12:47:25.606 2018-04-15 13:06:07.452   \n",
       "\n",
       "   start_station_id  start_station_name  start_station_latitude  \\\n",
       "0               499  Broadway & W 60 St               40.769155   \n",
       "1               499  Broadway & W 60 St               40.769155   \n",
       "2               499  Broadway & W 60 St               40.769155   \n",
       "3               499  Broadway & W 60 St               40.769155   \n",
       "4               499  Broadway & W 60 St               40.769155   \n",
       "\n",
       "   start_station_longitude  end_station_id             end_station_name  \\\n",
       "0               -73.981918            3175      W 70 St & Amsterdam Ave   \n",
       "1               -73.981918            3167      Amsterdam Ave & W 73 St   \n",
       "2               -73.981918             423              W 54 St & 9 Ave   \n",
       "3               -73.981918            3175      W 70 St & Amsterdam Ave   \n",
       "4               -73.981918            3163  Central Park West & W 68 St   \n",
       "\n",
       "   end_station_latitude  end_station_longitude  bikeid    usertype  \\\n",
       "0             40.777480             -73.982886   30250  Subscriber   \n",
       "1             40.779668             -73.980930   30491  Subscriber   \n",
       "2             40.765849             -73.986905   15480  Subscriber   \n",
       "3             40.777480             -73.982886   30922  Subscriber   \n",
       "4             40.773407             -73.977825   32707    Customer   \n",
       "\n",
       "   birth_year  gender  processed  \n",
       "0        1981       1      False  \n",
       "1        1967       1      False  \n",
       "2        1978       1      False  \n",
       "3        1988       1      False  \n",
       "4        1990       1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(f'postgresql://{psql_config[\"user\"]}:{psql_config[\"password\"]}@{psql_config[\"host\"]}/{psql_config[\"dbname\"]}')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM m024.citi_bike_data LIMIT 1000;\", engine)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, we will start processing it in bunch.\n",
    "For each chunk, we will apply some validation and transform the source data into fact and dimension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, sqrt, atan2\n",
    "from psycopg2.extras import execute_values\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Function to calculate distance using Haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "# Extract Data\n",
    "def extract_data(offset):\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM m024.citi_bike_data \n",
    "    WHERE processed = FALSE \n",
    "    ORDER BY ctid\n",
    "    LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "# Load data into dimension tables\n",
    "def load_dimension_data(df, table_name, cols, db_cols):\n",
    "    df = df[cols].astype('str').drop_duplicates()\n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                statement = f\"\"\"\n",
    "                INSERT INTO m024.p_{table_name} ({', '.join(db_cols)})\n",
    "                VALUES %s \n",
    "                ON CONFLICT DO NOTHING;\"\"\"\n",
    "                data_tuples = [tuple(row) for row in df.to_numpy()]\n",
    "                    \n",
    "                # Execute batch insert\n",
    "                execute_values(cur, statement, data_tuples)\n",
    "                \n",
    "                # Commit changes\n",
    "                conn.commit() \n",
    "                print(f\"Data inserted/updated successfully in {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in inserting/updating data for table {table_name}- {e}\")\n",
    "\n",
    "# Load dimension tables and return mapping IDs\n",
    "def get_dimension_id(df, table_name, lookup_col, db_lookup_col,db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "    query = f\"SELECT {db_lookup_col}, {db_return_col} FROM m024.p_{table_name} WHERE {db_lookup_col} IN %s\"\n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_values),))\n",
    "    return dict(zip(mapping[db_lookup_col], mapping[db_return_col]))\n",
    "\n",
    "def get_time_dimension_id(df, table_name, lookup_col, db_lookup_cols, db_return_col):\n",
    "    lookup_values = df[lookup_col].drop_duplicates().tolist()\n",
    "\n",
    "    # Build query based on date components to avoid precision issues with timestamps\n",
    "    query = f\"\"\"\n",
    "    SELECT {', '.join(db_lookup_cols)}, {db_return_col}\n",
    "    FROM m024.p_{table_name}\n",
    "    WHERE ({', '.join(db_lookup_cols)}) IN %s\n",
    "    \"\"\"\n",
    "    lookup_tuples = [\n",
    "        (row['year'], row['month'], row['day'], row['hour']) for _, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    mapping = pd.read_sql(query, engine, params=(tuple(lookup_tuples),))\n",
    "    return dict(zip(mapping[db_lookup_cols], mapping[db_return_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in gender_dimension\n",
      "Data inserted/updated successfully in user_type_dimension\n",
      "Data inserted/updated successfully in user_birthyear_dimension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['start_station_latitude'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['start_station_longitude'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['end_station_latitude'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['end_station_longitude'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in station_dimension\n",
      "Data inserted/updated successfully in station_dimension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['starttime'].fillna('1.1.1900', inplace=True)\n",
      "C:\\Users\\Besitzer\\AppData\\Local\\Temp\\ipykernel_26052\\1233814397.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['stoptime'].fillna('1.1.1900', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in bike_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in time_dimension\n",
      "Data inserted/updated successfully in trip_fact\n",
      "Successfully updated the processed flag for 100 rows (Offset: 0).\n",
      "Processed batch 0-10\n"
     ]
    }
   ],
   "source": [
    "# Transform Data\n",
    "def transform_data(df):\n",
    "\n",
    "    # transform gender and load the dimension\n",
    "    df.gender = df.gender.map(dict(zip([1, 2],['Male','Female']))).fillna('Unknown')\n",
    "    load_dimension_data(df, 'gender_dimension', ['gender'],['gender_type'])\n",
    "\n",
    "    # transform user type and load the dimension\n",
    "    df.usertype = df.usertype.apply(lambda x: x if x in ['Subscriber', 'Customer'] else 'Unknown')\n",
    "    load_dimension_data(df, 'user_type_dimension', ['usertype'],['user_type'])\n",
    "\n",
    "    # transform birth year and load the dimension\n",
    "    df.birth_year = df.birth_year.apply(lambda x: x if x > 1940 and x <2013 else 0).astype(int) # Assuming you need to be atleast 5 to ride the bike\n",
    "    load_dimension_data(df, 'user_birthyear_dimension', ['birth_year'],['user_birthyear'])\n",
    "\n",
    "    # Clean station names\n",
    "    df['start_station_name'] = df['start_station_name'].str.strip().fillna('Unknown')\n",
    "    df['end_station_name'] = df['end_station_name'].str.strip().fillna('Unknown')\n",
    "\n",
    "    # Validate Latitude and Longitude\n",
    "    df['start_station_latitude'] = df['start_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['start_station_longitude'] = df['start_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "    df['end_station_latitude'] = df['end_station_latitude'].apply(\n",
    "        lambda x: x if -90 <= x <= 90 else None\n",
    "    )\n",
    "    df['end_station_longitude'] = df['end_station_longitude'].apply(\n",
    "        lambda x: x if -180 <= x <= 180 else None\n",
    "    )\n",
    "\n",
    "    # For missing latitude/longitude values\n",
    "    df['start_station_latitude'].fillna('Unknown', inplace=True)\n",
    "    df['start_station_longitude'].fillna('Unknown', inplace=True)\n",
    "    df['end_station_latitude'].fillna('Unknown', inplace=True)\n",
    "    df['end_station_longitude'].fillna('Unknown', inplace=True)\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    load_dimension_data(df, 'station_dimension',\n",
    "                         ['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude'],\n",
    "                           ['station_key', 'station_name', 'latitude', 'longitude'])\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['starttime'].fillna('1.1.1900', inplace=True)\n",
    "    df['stoptime'].fillna('1.1.1900', inplace=True)\n",
    "\n",
    "    # Convert to datetime format\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "    \n",
    "    load_dimension_data(df, 'bike_dimension', ['bikeid'], ['bike_id'])\n",
    "\n",
    "    df['starttime_dt'] = pd.to_datetime(df['starttime'])\n",
    "    df['stoptime_dt'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "    # Extract fields for start time\n",
    "    df['start_date'] = df['starttime_dt'].dt.date\n",
    "    df['start_year'] = df['starttime_dt'].dt.year\n",
    "    df['start_month'] = df['starttime_dt'].dt.month\n",
    "    df['start_day'] = df['starttime_dt'].dt.day\n",
    "    df['start_hour'] = df['starttime_dt'].dt.hour\n",
    "\n",
    "    # Extract fields for stop time\n",
    "    df['stop_date'] = df['stoptime_dt'].dt.date\n",
    "    df['stop_year'] = df['stoptime_dt'].dt.year\n",
    "    df['stop_month'] = df['stoptime_dt'].dt.month\n",
    "    df['stop_day'] = df['stoptime_dt'].dt.day\n",
    "    df['stop_hour'] = df['stoptime_dt'].dt.hour\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['starttime', 'start_date', 'start_year', 'start_month', 'start_day', 'start_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    load_dimension_data(df, 'time_dimension',\n",
    "                         ['stoptime', 'stop_date', 'stop_year', 'stop_month', 'stop_day', 'stop_hour'],\n",
    "                         ['time', 'date', 'year', 'month', 'day', 'hour'])\n",
    "\n",
    "    # Calculate trip distance\n",
    "    df['distance'] = df.apply(lambda row: haversine(\n",
    "        row['start_station_latitude'], row['start_station_longitude'], \n",
    "        row['end_station_latitude'], row['end_station_longitude']\n",
    "    ), axis=1)\n",
    "\n",
    "    # Get dimension table mappings\n",
    "    station_map = get_dimension_id(df, 'station_dimension', 'start_station_id', 'station_key','station_id')\n",
    "    end_station_map = get_dimension_id(df, 'station_dimension', 'end_station_id', 'station_key','station_id')\n",
    "    start_time_map = get_dimension_id(df, 'time_dimension', 'starttime', 'time', 'time_id')\n",
    "    stop_time_map = get_dimension_id(df, 'time_dimension', 'stoptime', 'time', 'time_id')\n",
    "    user_type_map = get_dimension_id(df, 'user_type_dimension', 'usertype', 'user_type','user_type_id')\n",
    "    gender_map = get_dimension_id(df, 'gender_dimension', 'gender', 'gender_type','gender_id')\n",
    "    birth_year_map = get_dimension_id(df, 'user_birthyear_dimension', 'birth_year', 'user_birthyear', 'user_birthyear_id')\n",
    "\n",
    "    # Map dimension table IDs\n",
    "    df['start_time_id'] = df['starttime'].map(start_time_map)\n",
    "    df['end_time_id'] = df['stoptime'].map(stop_time_map)\n",
    "    df['start_station_id'] = df['start_station_id'].map(station_map)\n",
    "    df['end_station_id'] = df['end_station_id'].map(end_station_map)\n",
    "    df['bike_id'] = df['bikeid']\n",
    "    df['user_type_id'] = df['usertype'].map(user_type_map)\n",
    "    df['gender_type_id'] = df['gender'].map(gender_map)\n",
    "    df['user_birthyear_id'] = df['birth_year'].map(birth_year_map)\n",
    "    df['duration'] = df['tripduration']\n",
    "\n",
    "    return df[['duration', 'distance', 'start_time_id', 'end_time_id', 'start_station_id', 'end_station_id', 'bike_id', 'user_type_id', 'gender_type_id', 'user_birthyear_id']]\n",
    "\n",
    "# Update processed records\n",
    "def update_processed(df, limit=BATCH_SIZE, offset=0):\n",
    "    query = f\"\"\"\n",
    "    WITH cte AS (\n",
    "        SELECT ctid\n",
    "        FROM m024.citi_bike_data\n",
    "        WHERE processed = FALSE\n",
    "        ORDER BY ctid\n",
    "        LIMIT {BATCH_SIZE} OFFSET {offset}\n",
    "    )\n",
    "    UPDATE m024.citi_bike_data\n",
    "    SET processed = TRUE\n",
    "    WHERE ctid IN (SELECT ctid FROM cte);\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with get_psql_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Execute the update statement\n",
    "                cur.execute(query)\n",
    "                conn.commit()  # Commit the changes\n",
    "                print(f\"Successfully updated the processed flag for {limit} rows (Offset: {offset}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in updating processed flag: {e}\")\n",
    "\n",
    "# Process batch\n",
    "def process_batch(offset):\n",
    "    df = extract_data(offset)\n",
    "    if not df.empty:\n",
    "        df_transformed = transform_data(df)\n",
    "        load_dimension_data(df_transformed, 'trip_fact', df_transformed.columns, df_transformed.columns)\n",
    "        #return 0\n",
    "        update_processed(df)\n",
    "        print(f\"Processed batch {offset}-{offset+BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "process_batch(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
